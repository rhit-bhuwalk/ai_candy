model:
  gpt4all_model:
    gpt4all_model_name: orca-mini-3b-gguf2-q4_0.gguf
    gpt4all_model_folder_path: C:\Users\bhuwalk\projects\ai_candy\model_cache
    gpt4all_backend: llama
    gpt4all_allow_streaming: true
    gpt4all_allow_downloading: true
    gpt4all_temperature: 1
    gpt4all_top_p: 0.1
    gpt4all_top_k: 40
    gpt4all_n_batch: 8
    gpt4all_n_threads: 4
    gpt4all_n_predict: 256
    gpt4all_max_tokens: 200
    gpt4all_repeat_last_n: 64
    gpt4all_penalty: 1.18
